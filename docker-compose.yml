networks:
  pipeline-net:
    driver: bridge

volumes:
  kafka-data:
  minio-data:
  prometheus-data:
  grafana-data:

services:
  # ============================================
  # KAFKA 4.1.0 (KRaft Mode)
  # ============================================
  kafka:
    image: apache/kafka:4.1.0
    container_name: kafka
    networks:
      - pipeline-net
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_LISTENERS: "PLAINTEXT://:29092,CONTROLLER://:9093,EXTERNAL://:9092"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:29092,EXTERNAL://localhost:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_JMX_PORT: 9999
      KAFKA_JMX_HOSTNAME: kafka
    volumes:
      - kafka-data:/var/lib/kafka/data
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092 || exit 1",
        ]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 2G

  # ============================================
  # KAFKA TOPIC INIT (EXPLICIT CREATION)
  # ============================================
  kafka-init:
    image: apache/kafka:4.1.0
    container_name: kafka-init
    networks:
      - pipeline-net
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: /bin/bash
    command:
      - -c
      - |
        echo "‚è≥ Waiting for Kafka broker to be ready..."
        sleep 15
        /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --create \
          --topic iot-events \
          --partitions 3 \
          --replication-factor 1 \
          --if-not-exists \
          --config retention.ms=86400000 \
          --config segment.ms=3600000 \
          --config compression.type=snappy
        if [ $? -eq 0 ]; then
          echo "‚úÖ Topic iot-events created successfully"
          /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --list
          exit 0
        else
          echo "‚ùå Failed to create topic"
          exit 1
        fi
    restart: on-failure
    deploy:
      resources:
        limits:
          memory: 512M

  # ============================================
  # MINIO (S3-COMPATIBLE OBJECT STORAGE)
  # ============================================
  minio:
    image: minio/minio:RELEASE.2024-11-07T00-52-20Z
    container_name: minio
    networks:
      - pipeline-net
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1G

  # ============================================
  # MINIO BUCKET INITIALIZATION
  # ============================================
  minio-init:
    image: minio/mc:latest
    container_name: minio-init
    networks:
      - pipeline-net
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      echo '‚è≥ Waiting for MinIO to be fully ready...';
      sleep 10;

      for i in 1 2 3 4 5; do
        echo 'üîÑ Attempt $$i: Connecting to MinIO...';
        /usr/bin/mc alias set myminio http://minio:9000 minioadmin minioadmin && break;
        if [ $$i -lt 5 ]; then sleep 5; fi;
      done;

      /usr/bin/mc mb myminio/data-lake --ignore-existing;
      /usr/bin/mc mb myminio/checkpoints --ignore-existing;
      /usr/bin/mc mb myminio/test-parquet-bucket --ignore-existing;
      echo '‚úÖ Buckets created successfully';
      exit 0;
      "
    restart: on-failure
    deploy:
      resources:
        limits:
          memory: 256M

  # ============================================
  # SPARK MASTER (Apache Spark 4.0.1)
  # ============================================
  spark-master:
    build:
      context: ./spark
      dockerfile: Dockerfile
    container_name: spark-master
    networks:
      - pipeline-net
    ports:
      - "8080:8080"
      - "7077:7077"
      - "4040:4040"
    environment:
      SPARK_MODE: master
      SPARK_MASTER_HOST: spark-master
      SPARK_MASTER_PORT: 7077
    volumes:
      - ./processing:/opt/spark/work-dir
      - ./query:/opt/spark/work-dir/query
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 4G

  # ============================================
  # SPARK WORKER
  # ============================================
  spark-worker:
    build:
      context: ./spark
      dockerfile: Dockerfile
    container_name: spark-worker
    networks:
      - pipeline-net
    depends_on:
      spark-master:
        condition: service_healthy
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_MEMORY: ${SPARK_WORKER_MEMORY:-2G}
      SPARK_WORKER_CORES: ${SPARK_WORKER_CORES:-2}
    volumes:
      - ./processing:/opt/spark/work-dir
      - ./query:/opt/spark/work-dir/query
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 4G
    restart: unless-stopped

  # ============================================
  # IOT EVENT PRODUCER
  # ============================================
  producer:
    build:
      context: ./ingestion
      dockerfile: Dockerfile
    container_name: iot-producer
    networks:
      - pipeline-net
    depends_on:
      kafka-init:
        condition: service_completed_successfully
    environment:
      KAFKA_BROKERS: kafka:29092
      KAFKA_TOPIC: iot-events
      EVENT_RATE: ${EVENT_RATE:-10}
      NUM_DEVICES: ${NUM_DEVICES:-50}
      METRICS_PORT: 8082
      PYTHONUNBUFFERED: 1
    ports:
      - "8082:8082"
    volumes:
      - ./ingestion:/app
      - ./tests:/app/tests
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 512M
    restart: unless-stopped

  # ============================================
  # SPARK STRUCTURED STREAMING JOB
  # ============================================
  spark-streaming:
    build:
      context: ./processing
      dockerfile: Dockerfile
    container_name: spark-streaming
    networks:
      - pipeline-net
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      minio-init:
        condition: service_completed_successfully
      spark-master:
        condition: service_healthy
    environment:
      SPARK_MASTER_URL: spark://spark-master:7077
      KAFKA_BROKERS: kafka:29092
      KAFKA_TOPIC: iot-events
      S3_ENDPOINT: http://minio:9000
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      CHECKPOINT_LOCATION: s3a://checkpoints/streaming-job
      OUTPUT_PATH: s3a://data-lake/processed
      PYTHONUNBUFFERED: 1
    volumes:
      - ./processing:/opt/spark/work-dir
      - ./logs:/opt/spark/work-dir/logs
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 4G
    restart: unless-stopped

  # ============================================
  # KAFKA EXPORTER (Prometheus metrics)
  # ============================================
  kafka-exporter:
    image: danielqsj/kafka-exporter:v1.9.0
    container_name: kafka-exporter
    networks:
      - pipeline-net
    ports:
      - "9308:9308"
    depends_on:
      kafka:
        condition: service_healthy
    command:
      - "--kafka.server=kafka:29092"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M

  # ============================================
  # PROMETHEUS (Metrics Collection)
  # ============================================
  prometheus:
    image: prom/prometheus:v3.7.3
    container_name: prometheus
    networks:
      - pipeline-net
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=7d"
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1G

  # ============================================
  # GRAFANA (Dashboard & Visualization)
  # ============================================
  grafana:
    image: grafana/grafana:12.2.0
    container_name: grafana
    networks:
      - pipeline-net
    ports:
      - "3000:3000"
    depends_on:
      prometheus:
        condition: service_healthy
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_PATHS_PROVISIONING: /etc/grafana/provisioning
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    healthcheck:
      test:
        ["CMD", "wget", "-q", "--spider", "http://localhost:3000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1G

  # ============================================
  # NODE EXPORTER (System Metrics)
  # ============================================
  node-exporter:
    image: prom/node-exporter:v1.10.2
    container_name: node-exporter
    networks:
      - pipeline-net
    ports:
      - "9100:9100"
    command:
      - "--path.procfs=/host/proc"
      - "--path.sysfs=/host/sys"
      - "--path.rootfs=/rootfs"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M

  # ============================================
  # KAFKA UI (Optional - for debugging)
  # ============================================
  kafka-ui:
    image: ghcr.io/kafbat/kafka-ui:latest
    container_name: kafka-ui
    networks:
      - pipeline-net
    ports:
      - "8090:8080"
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_JMXPORT: 9999
      DYNAMIC_CONFIG_ENABLED: "true"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
