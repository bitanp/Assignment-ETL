# Spark Configuration for Streaming Job
# These settings optimize for small-medium scale deployments

# Memory and Executor Settings
spark.executor.memory=2g
spark.driver.memory=2g
spark.executor.cores=2

# Shuffle and Partitioning
spark.sql.shuffle.partitions=200
spark.default.parallelism=200

# S3/MinIO Configuration
spark.hadoop.fs.s3a.connection.maximum=100
spark.hadoop.fs.s3a.connection.establish.timeout=5000
spark.hadoop.fs.s3a.connection.timeout=10000
spark.hadoop.fs.s3a.fast.upload=true
spark.hadoop.fs.s3a.block.size=134217728
spark.hadoop.fs.s3a.multipart.size=67108864

# Streaming Settings
spark.sql.streaming.metricsEnabled=true
spark.streaming.stopGracefullyOnShutdown=true
spark.sql.streaming.minBatchesToRetain=10

# Checkpointing
spark.sql.streaming.checkpointFileManagerClass=org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider

# Logging
spark.eventLog.enabled=false